# Analysis-of-Generalization-Performance-of-Xception-Model-for-Fake-Image-Identificaiton

![제목 없음 (1)](https://user-images.githubusercontent.com/77098071/147543712-394557c4-40bd-4967-a39d-99f5506a07ec.png)

__IVC(Image & Vision Computing) Lab / Pukyong Nat'l Univ Electronic Engineering / Busan, Republic of Korea__   
Jeonghan Lee, Hanhoon Park(Major Professor)

* Paper(Korean) :     
* Video(Korean) :    


### Acknowledgement
* "This research was supported by Basic Science Research Program through the National Research Foundation of Korea(NRF) funded by the Ministry of Education(No. 2021R1F1A1045749)"

<br/>

__This content is inspired by the documents below :__
1. I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, and Y. Bengio, "Generative adversarial nets," Proc. of NIPS, 27, 2014.
2. F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser, and J. Xiao, “LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop,” arXiv preprint arXiv:1506.03365, 2015.
3. T. Karras, T. Aila, S. Laine, and J. Lehtinen, “Progressive growing of GANs for improved quality, stability, and variation,” arXiv preprint arXiv:1710.10196, 2017.
4. T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen, and T. Aila, “Analyzing and improving the image quality of StyleGAN,” Proc. of CVPR, pp. 8110-8119, 2020.
5. T. Karras, S. Laine, and T. Aila, “A style-based generator architecture for generative adversarial networks,” Proc. of CVPR, pp. 4401-4410, 2019.
6. F. Chollet, “Xception: Deep learning with depthwise separable convolutions,” Proc. of CVPR, pp. 1251-1258, 2017.
